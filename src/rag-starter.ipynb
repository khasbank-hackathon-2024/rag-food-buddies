{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG гарааны код\n",
    "\n",
    "Энэхүү гарааны jupyter notebook нь энгийн RAG архитектурыг [LangChain](https://python.langchain.com/docs/introduction/) framework-н тусламжтай, хэлний загваруудыг [Hugging Face Transformers](https://huggingface.co/docs/transformers/index)-р татаж, ажиллуулах байдлаар хэрэгжүүлсэн бөгөөд энэхүү notebook-д суурилан өөрсдийн RAG архитектур, загвар, шийдлээ хэрэгжүүлж болно.\n",
    "\n",
    "Шаардлагатай python сангуудыг [requirements.txt](../requirements.txt) файлд жагсаасан байгаа.\n",
    "\n",
    "![](https://python.langchain.com/assets/images/rag_concepts-4499b260d1053838a3e361fb54f376ec.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store үүсгэх\n",
    "\n",
    "RAG системийн үндсэн хоёр хэсгийн нэг, заавал бэлдсэн байх ёстой зүйл бол өгөгдлөө embedding буюу тоон хэлбэрт шилжүүлж, vector store-д хадгалсан байх юм.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*vAvDBIbr8MnL_Q51mBtBhw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Өгөгдөл унших\n",
    "\n",
    "`data` хавтсанд байрлах `csv` файлыг уншиж LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html)-н жагсаалт болгоно.\n",
    "\n",
    "- `khas_bank_news.csv`\n",
    "- `khas_bank_pages.csv`\n",
    "- `khas_bank_products.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/\"\n",
    "loader = CSVLoader(file_path=f\"{DATA_DIR}khas_bank_news.csv\",\n",
    "                   source_column=\"link\",\n",
    "                   metadata_columns=[\"title\", \"date\", \"link\"],\n",
    "                   content_columns=[\"content\"],\n",
    "                   csv_args={\n",
    "                       \"fieldnames\": [\"title\", \"link\", \"date\", \"content\"],\n",
    "                       }\n",
    "                   )\n",
    "news_data = loader.load()[1:]\n",
    "\n",
    "loader = CSVLoader(file_path=f\"{DATA_DIR}khas_bank_products.csv\",\n",
    "                   source_column=\"link\",\n",
    "                   metadata_columns=[\"id\", \"side_menu_text\", \"link\"],\n",
    "                   content_columns=[\"content\"],\n",
    "                   csv_args={\n",
    "                       \"fieldnames\": [\"id\", \"content\", \"side_menu_text\", \"link\"],\n",
    "                       }\n",
    "                   )\n",
    "product_data = loader.load()[1:]\n",
    "\n",
    "loader = CSVLoader(file_path=f\"{DATA_DIR}khas_bank_pages.csv\",\n",
    "                   source_column=\"link\",\n",
    "                   metadata_columns=[\"title\", \"link\"],\n",
    "                   content_columns=[\"content\"],\n",
    "                   csv_args={\n",
    "                       \"fieldnames\": [\"title\", \"content\", \"link\"],\n",
    "                       }\n",
    "                   )\n",
    "pages_data = loader.load()[1:]\n",
    "\n",
    "all_data = news_data + product_data + pages_data\n",
    "print(len(news_data), len(product_data), len(pages_data))\n",
    "print(f\"Нийт хуудасны тоо: {len(all_data)}\")\n",
    "print(all_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Өгөгдөл хуваах\n",
    "\n",
    "Document хэт урт бол vector store-с хайх хайлтын чанар муудах магадлалтай тул доорх хэсэгт агуулгыг тэмдэгтийн тоогоор таслан хэд хэдэн Document болгов.\n",
    "\n",
    "Жич: RAG-н чанарыг сайжруулахын тулд зөвхөн тэмдэгтийн тоогоор хуваахаас гадна өгүүлбэр, цогцолбор, бүлэг гэх мэтчилэн өгөгдөлд тохирсон арга олох нь чухал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100\n",
    ")\n",
    "docs = text_splitter.split_documents(documents=all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "Embedding нь энгийн үгээр ямар нэгэн өгөгдлийг вектор дүрслэл рүү хөрвүүлсэн хэлбэр бөгөөд тухайн вектор нь олон хэмжээст огторгуйд ижил, төстэй утга бүхий өгөгдөлтэй ойр, эсрэг утгатай өгөгдлөөс хол байрладаг.\n",
    "\n",
    "Энэхүү жишээ RAG-д [`sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) загварыг сонгон авлаа.\n",
    "\n",
    "![embedding model](https://python.langchain.com/assets/images/embeddings_concept-975a9aaba52de05b457a1aeff9a7393a.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store\n",
    "\n",
    "Харин vector store нь embedding болон өгөгдөл эсвэл түүний заагчийг хамтад нь хадгалж, хайлтын query орж ирэхэд мөн түүнийг вектор хэлбэрт хөрвүүлэн, санд байх векторуудаас хамгийн ойрыг хайдаг өгөгдлийн сан юм.\n",
    "\n",
    "Энэхүү жишээнд FAISS vector store сонгож ашиглалаа.\n",
    "\n",
    "![vectorestore](https://python.langchain.com/assets/images/vectorstores-2540b4bc355b966c99b0f02cfdddb273.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Бүх document-с embedding үүсгэж, vector store-д хадгалах\n",
    "# (өмнө нь үүсгэсэн бол заавал дахин үүсгэх шаардлагагүй, доорх load_local функцээр хадгалсан файлаас уншиж болно)\n",
    "vector_store = FAISS.from_documents(docs, embeddings)\n",
    "vector_store.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Үүсгэсэн vector store-г файлаас унших\n",
    "vector_store = FAISS.load_local(\n",
    "    \"faiss_index\", embeddings, allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector Store үүсгэсэн бол түүнээс ойролцоо утгатай өгөгдөл хайж үзье.\n",
    "\n",
    "![retriever](https://python.langchain.com/assets/images/retriever_concept-1093f15a8f63ddb90bd23decbd249ea5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.xacbank.mn/article/ipo-opening', 'row': 73, 'title': 'ХасБанкны IPO: Нээлтийн арга хэмжээ амжилттай боллоо', 'date': '2023.05.25', 'link': 'https://www.xacbank.mn/article/ipo-opening'}, page_content='content: ХасБанкны IPO: Нээлтийн арга хэмжээ амжилттай боллооТус арга хэмжээнд ХасБанк өөрийн үйл ажиллагаа, хувьцаа, ирээдүйн стратеги, зорилтынхоо талаар харилцагч, хөрөнгө оруулагч, олон нийтэд дэлгэрэнгүй мэдээлэл өгсний зэрэгцээ ХасБанкны IPO-д хамтран ажиллаж буй андеррайтерууд болох Райнос Инвестмент үнэт цаасны компани, Өлзий энд Ко Капитал үнэт цаасны компаниуд үнэт цаасны данс нээн, урьдчилсан захиалга авч, хөрөнгийн зах зээлтэй холбоотой зөвлөгөө мэдээлэл өглөө.ХасБанк нийт хувьцааныхаа 5.01 хувийг 677 төгрөгийн нэгжийн үнээр анхдагч зах зээлд арилжаалж 35.7 тэрбум төгрөгийг татан төвлөрүүлэх бөгөөд хувьцааны захиалга 2023 оны 5-р сарын 29-ний 10:00 цагаас 6-р сарын 5-ны 16:00 цаг хүртэл явагдана.Эрхэм харилцагч, хөрөнгө оруулагч та өнөөдрөөс эхлэн ХасБанкны хувьцааны урьдчилсан захиалгыг ХасБанкны дижитал банк болон үндсэн андеррайтер Райнос Инвестмент ҮЦК, туслах андеррайтер Өлзий энд Ко Капитал ҮЦК-уудаар өгч болохоос гадна 5-р сарын 29-нд анхдагч арилжаа нээгдмэгц өөрийн'),\n",
       " Document(metadata={'source': 'https://www.xacbank.mn/article/ipo-ceo-interview', 'row': 74, 'title': 'Г.Цэвэгжав: Сайн засаглал, олон улсын туршлага, нэр хүндтэй хөрөнгө оруулагчид бидний гол давуу тал', 'date': '2023.05.24', 'link': 'https://www.xacbank.mn/article/ipo-ceo-interview'}, page_content='УИХ зөв шийдвэр гаргаж, IPO гаргах хугацааг нэг жилээр сунгасан. Тэгж байж банкнууд сүүлийн 5-6 сард л IPO гаргах боломжтой боллоо шүү дээ. Хэрвээ анхны давчуу хугацаагаар явсан бол маш том эрсдэлүүд гарах нь ойлгомжтой байв. Хугацааг сунгаж, банкнууд активын чанарын үнэлгээ (AQR)хийлгэсэн нь маш зөв зүйл болсон. Банкнуудад IPO-д бэлдэх хугацаа өгч, улмаар эдийн засгийн нөхцөл ч түрүү жилийнхтэй харьцуулахад хамаагүй сайжирсан.-Системийн топ 5 банкнаас өдгөө ХасБанкны IPO л хүлээгдэж байна. Банкнууд ээлж дараатай гаргая гэдгээ тохирсон байсан уу. IPO гаргахад хамгийн сайн бэлтгэлтэй байсан ХасБанк хамгийн сүүлд гаргаж буйд ямар нэгэн шалтгаан бий юу?-Бид хоорондоо ямар нэг дараалал яриагүй. Банкнууд өөрсдийнх нь үйл ажиллагаа, стратеги, санхүүгийн нөхцөл байдлаасаа шалтгаалан өөрсдөө хугацаагаа тогтоосон нь энэ. Эхлээд “Төрийн банк” IPO хийсэн. Засгийн газраас төрийн өмчит компаниудыг хувьчлах шийдвэр гаргаж, энэ хүрээнд тэд арай түрүүлж хөдөлсөн болов уу. “Төрийн банк” түрүүлж'),\n",
       " Document(metadata={'source': 'https://www.xacbank.mn/article/ipo-opening', 'row': 73, 'title': 'ХасБанкны IPO: Нээлтийн арга хэмжээ амжилттай боллоо', 'date': '2023.05.25', 'link': 'https://www.xacbank.mn/article/ipo-opening'}, page_content='Өлзий энд Ко Капитал ҮЦК-уудаар өгч болохоос гадна 5-р сарын 29-нд анхдагч арилжаа нээгдмэгц өөрийн бүртгэлтэй аль ч үнэт цаасны компаниар дамжуулан захиалга өгөх боломжтой.Мөн ХасБанкны IPO-ын талаарх бүхий л мэдээллийг ipo.xacbank.mn веб хуудсаар авч болохын дээр үнэт цаасны данс, захиалгатай холбоотой асуудлаар Райнос Инвестмент ҮЦК /7510 0575/, Өлзий энд Ко Капитал ҮЦК /7777 6377/-уудтай холбогдоно уу.Энэ бол зөвхөн эхлэл.')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector store-с document хайгч, k параметраар хамгийн ойр утгатай хэдэн document буцаахыг дамжуулна\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "docs = retriever.invoke(\"хасбанк хэзээ IPO хийсэн бэ\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Өгөгдөл хайх, хариулах\n",
    "\n",
    "Өмнөх хэсэгт өгөгдлөө бэлтгэж, vector store-т хадгалсан бол энэ хэсэгт хэрэглэгчийн асуусан асуултаар vector store-с хайлт хийж, LLM-р хариулт өгөх болно.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:2000/format:webp/1*8dUBh25peTpsucMpL1ypUg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM\n",
    "\n",
    "Хайж олсон мэдээлэл, хэрэглэгчийн асуултад тохирох хариулт үүсгэхийн тулд бичвэр үүсгэгч Large Language Model ашиглана.\n",
    "\n",
    "Энд Meta компанийн сургасан [8 тэрбум параметртай Llama 3.1(https://huggingface.co/meta-llama/Llama-3.1-8B)] загварыг сонгов. (Hugging Face дээр загвар ашиглах зөвшөөрөл хүссэн маягт бөглөх ёстой)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba3c9ade9594136a736fc1464d5dc1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hugging Face-с хандах эрх авсан хаалттай загваруудад хандахын тулд нэвтэрсэн байх шаардлагатай\n",
    "# Нэмэлт мэдээллийг https://huggingface.co/docs/huggingface_hub/package_reference/authentication\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e0ffcaccbe484d91309c220b8d9fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to offload the whole model to the disk. Please use the `disk_offload` function instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-3.1-8B\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     pad_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# HuggingFace pipeline-г LangChain-ы pipeline болгох\u001b[39;00m\n",
      "File \u001b[0;32m~/hackaton/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/hackaton/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:4342\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4339\u001b[0m         device_map_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffload_buffers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   4341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_deepspeed_zero3_enabled():\n\u001b[0;32m-> 4342\u001b[0m         \u001b[43mdispatch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdevice_map_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4345\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mpostprocess_model(model)\n",
      "File \u001b[0;32m~/hackaton/.venv/lib/python3.10/site-packages/accelerate/big_modeling.py:500\u001b[0m, in \u001b[0;36mdispatch_model\u001b[0;34m(model, device_map, main_device, state_dict, offload_dir, offload_index, offload_buffers, skip_keys, preload_module_classes, force_hooks)\u001b[0m\n\u001b[1;32m    498\u001b[0m         model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 500\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    501\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to offload the whole model to the disk. Please use the `disk_offload` function instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m         )\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# Convert OrderedDict back to dict for easier usage\u001b[39;00m\n\u001b[1;32m    504\u001b[0m model\u001b[38;5;241m.\u001b[39mhf_device_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(device_map)\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to offload the whole model to the disk. Please use the `disk_offload` function instead."
     ]
    }
   ],
   "source": [
    "# Жишээ болгож Llama 3.1 8B загварыг ашиглав\n",
    "model_id = \"meta-llama/Llama-3.1-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    # llm-н үүсгэж болох токений дээд хязгаар\n",
    "    max_new_tokens=1024,\n",
    "    # хариултын randomization-г арилгах\n",
    "    do_sample=True,\n",
    "    top_k=1,\n",
    "    repetition_penalty=1.15,\n",
    "    # гаралт бидний өгсөн prompt-г хамт хэвлэхгүй байх\n",
    "    return_full_text=False,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "# HuggingFace pipeline-г LangChain-ы pipeline болгох\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain: Retrieval -> Prompt -> LLM\n",
    "\n",
    "Prompt-н `{context}`-н оронд хайж олсон мэдээлэл, `{input}`-н оронд хэрэглэгчийн асуусан асуулт орох болно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the user question. If you don't know the answer to the question, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    'Context:\\n\"\"\"\\n{context}\\n\"\"\"'\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", \"Question: \\\"\\\"\\\"{input}\\\"\\\"\\\"\"),\n",
    "        (\"assistant\", \"Answer: \"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# vector store-с document хайгч, k параметраар хамгийн ойр утгатай хэдэн document буцаахыг дамжуулна\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# Chain үүсгэх\n",
    "# input -> retrieval -> prompt -> llm -> answer\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain ажиллуулах\n",
    "response = rag_chain.invoke({\"input\": \"дебит карт яаж авах вэ\"})\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input, context, answer гурвыг бүгдийг нь харах\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
